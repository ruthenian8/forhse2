{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ok = pd.read_csv(\"../../dataset_ok.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–Ω–∞–µ–±–∞–ª–æ–≤–æ –≤–µ–∫–∞, –¥–ª—è –¥–æ–ª–±–∞—ë–±–æ–≤\\n</td>\n",
       "      <td>INSULT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–≤—Å—è –¥—É–º–∞ –≤ —Ç–∞–∫–æ–º –∂–µ –ø–æ–ª–æ–∂–µ–Ω–∏–∏üòÅ\\n</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–∞ –≤ –∫–∞–∫–æ–º –º–µ—Å—Ç–µ –º–∞—Å—Å–æ–≤–æ–µ —Å—Ç–æ–ª–∫–Ω–æ–≤–µ–Ω–∏–µ? —à—Ä–∞–π–±–∏–∫...</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–∑–Ω–∞—á–∏—Ç –ª–∏ —ç—Ç–æ, —á—Ç–æ –∫–æ–Ω—Ç—Ä–æ–ª—å –∑–∞ –≤—ã–≤–æ–∑–æ–º –∫—Ä—É–ø–Ω–æ–≥...</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–≤–∞–º –Ω–µ –Ω—É–∂–µ–Ω —â–µ–Ω–æ—á–µ–∫? –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–∏–µ üê∂ü•∞\\n</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>–æ–Ω, —Ö–æ—Ç—å –∂–∏–≤–æ–π –æ—Å—Ç–∞–ª—Å—è??.\\n</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>–±—ã–ª–æ –¥–µ–ª–æ.\\n</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>—Å —Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –Ω–µ—Ç –ø—Ä–æ–±–ª–µ–º, –∏–ª–∏ —Ç–æ–ª—å–∫–æ –≤ —Ö–æ–ª–æ–¥–∏–ª—å...</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>–ø–æ–ª–Ω–æ—Å—Ç—å—é –≤–∞—Å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é\\n</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>—ç—Ç–æ—Ç —Ä–µ—Ü–µ–ø—Ç –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ñ–æ—Ç–æ. –æ–æ–æ—Ö –∏ –Ω–∞–º—É...</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   label\n",
       "0                    –Ω–∞–µ–±–∞–ª–æ–≤–æ –≤–µ–∫–∞, –¥–ª—è –¥–æ–ª–±–∞—ë–±–æ–≤\\n  INSULT\n",
       "1                   –≤—Å—è –¥—É–º–∞ –≤ —Ç–∞–∫–æ–º –∂–µ –ø–æ–ª–æ–∂–µ–Ω–∏–∏üòÅ\\n  NORMAL\n",
       "2  –∞ –≤ –∫–∞–∫–æ–º –º–µ—Å—Ç–µ –º–∞—Å—Å–æ–≤–æ–µ —Å—Ç–æ–ª–∫–Ω–æ–≤–µ–Ω–∏–µ? —à—Ä–∞–π–±–∏–∫...  NORMAL\n",
       "3  –∑–Ω–∞—á–∏—Ç –ª–∏ —ç—Ç–æ, —á—Ç–æ –∫–æ–Ω—Ç—Ä–æ–ª—å –∑–∞ –≤—ã–≤–æ–∑–æ–º –∫—Ä—É–ø–Ω–æ–≥...  NORMAL\n",
       "4           –≤–∞–º –Ω–µ –Ω—É–∂–µ–Ω —â–µ–Ω–æ—á–µ–∫? –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–∏–µ üê∂ü•∞\\n  NORMAL\n",
       "5                        –æ–Ω, —Ö–æ—Ç—å –∂–∏–≤–æ–π –æ—Å—Ç–∞–ª—Å—è??.\\n  NORMAL\n",
       "6                                       –±—ã–ª–æ –¥–µ–ª–æ.\\n  NORMAL\n",
       "7  —Å —Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –Ω–µ—Ç –ø—Ä–æ–±–ª–µ–º, –∏–ª–∏ —Ç–æ–ª—å–∫–æ –≤ —Ö–æ–ª–æ–¥–∏–ª—å...  NORMAL\n",
       "8                        –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤–∞—Å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é\\n  NORMAL\n",
       "9  —ç—Ç–æ—Ç —Ä–µ—Ü–µ–ø—Ç –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ñ–æ—Ç–æ. –æ–æ–æ—Ö –∏ –Ω–∞–º—É...  NORMAL"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ok.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –£–ø—Ä–æ—â—ë–Ω–Ω—ã–π BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../lenta.txt\", encoding=\"UTF-8\") as file:\n",
    "    corpus_lenta = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pairs(corpus_joined: list):\n",
    "    corpus_split = corpus_joined.split(\" \")\n",
    "    counts = defaultdict()\n",
    "    for i in range(len(corpus_split) - 1):\n",
    "        if (corpus_split[i], corpus_split[i+1]) in counts:\n",
    "            counts[corpus_split[i], corpus_split[i+1]] += 1\n",
    "        else:\n",
    "            counts[corpus_split[i], corpus_split[i+1]] = 1\n",
    "    return counts\n",
    "\n",
    "def bpe_initialize(corpus: str, n_iterations: int, k_pairs: int):\n",
    "    merged_vocab = set()\n",
    "    punct = re.compile(r'[ .,:!;+=?\"\"'']')\n",
    "    corpus = re.sub(punct, \"\", corpus)\n",
    "    corpus_symbols = [sym for sym in corpus]\n",
    "    corpus_joined = \" \".join(corpus_symbols)\n",
    "    for n in range(n_iterations):\n",
    "        pairs = count_pairs(corpus_joined)\n",
    "        top_k = sorted(list(pairs.keys()), key=pairs.get, reverse=True)[:k_pairs]\n",
    "        for pair in top_k:\n",
    "            new_pair = pair[0] + pair[1]\n",
    "            corpus_joined = re.sub(f\"{pair[0]} {pair[1]}\", new_pair, corpus_joined)\n",
    "            merged_vocab.add(new_pair)\n",
    "    return merged_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–∞–Ω', '–º–∞', '—Å—Ç–≤', '–≤–∞', '–∞–º', '—Ä—É', '—Å–æ', '–ª–∏', '—Ü–∏', '–Ω—ã—Ö', '—Ç–æ', '–µ–π', '–æ–º', '–≤–∏', '—á–∞', '—Ç–∞', '–æ–∂', '–µ—Ä', '–≤—ã', '–∏–ª', '—É—é', '–∞–µ—Ç', '–æ—Ç', '–∞—è', '—â–∏', '–Ω–æ–π', '—Ä–µ', '–æ—Ä', '—Å—Ç', '–∫–∏', '–µ–¥', '–æ—Å', '–∏–Ω', '–∞–≤', '–Ω–∞', '–Ω—ã', '–∫–∞', '–µ–º', '—É–¥', '–µ—á', '–ø—Ä', '–∏—Ö', '–∏–º', '–¥–∞', '–ø–∞', '—É–ø', '–æ–Ω', '–∞—Ä', '–≥–æ', '–ª–∞', '–æ–≥', '–¥–∏', '–Ω–∏', '–∫—É', '–±—ã', '–æ–±', '–∑–∞', '–º–∏', '–µ–Ω', '–µ–≤', '–µ—Å', '—Å–∏', '–µ—Ç', '–∏—Ç', '–∞—Ç', '—è–≤', '—É—á', '–ø–æ', '–ª—å', '–æ–¥', '–∏–∏', '–∏—Å', '–ª—è', '–∏–∑', '–Ω–µ', '–µ–ª', '–ª–µ', '—Ä–æ', '–∞—Å', '—Ä–∏', '–æ–±—â', '—Å—è', '—Ä–∞', '—Ü–∏–∏', '—É–∂', '–∫–æ', '–∏–π', '–æ–æ–±', '—Ç–µ', '–∞–ª', '–∞–∫', '—Å–∫–∏', '–æ–ª', '–≤–æ', '–¥–µ', '—Å–∫', '–∞–∑', '—Ç–∏', '–æ–≤', '–Ω–æ']\n"
     ]
    }
   ],
   "source": [
    "print(list(bpe_initialize(corpus_lenta, 2, 50)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: —Å—Ä–µ–¥–∏ —á–∞—Å—Ç–æ—Ç–Ω—ã—Ö –ø–∞—Ä –º–Ω–æ–≥–æ —Ç–∞–∫–∏—Ö, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–æ—Ç–≤–µ—Å—Ç–≤—É—é—Ç —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã–º –º–æ—Ä—Ñ–µ–º–∞–º: \"—É—é\", \"—Å—è\", \"–µ—Ç\". –¢–∞–∫–∂–µ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —á–∞—Å—Ç–æ—Ç–Ω—ã—Ö —Å–ª–æ–≤, –≤—ã—Ö–æ–¥—è—â–∏–µ –∑–∞ –ø—Ä–µ–¥–µ–ª—ã –æ—Ç–¥–µ–ª—å–Ω–æ–π –º–æ—Ä—Ñ–µ–º—ã: \"—Ü–∏–∏\", \"–Ω–æ–π\", \"–Ω—ã—Ö\", \"–∞–µ—Ç\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–∞–Ω', '–±—É', '—Ö–æ', '–º–∞', '–≤–∞', '—Ä—É', '—Å–æ', '—Å–∫–æ', '–¥–æ', '–ø–æ–¥', '–ª–∏', '—Ü–∏', '–≥–∞', '–Ω—ã—Ö', '—Ç–æ', '–µ–π', '–≤–∏', '—á–∞', '–ø—Ä–∏', '—Ç–∞', '–µ—Ä', '–≤—ã', '–∏–ª', '–∫–æ–º', '–æ—Ç', '–ø—É', '–ª–æ', '–Ω–æ–π', '—Ä–µ', '–æ—Ä', '—Å—Ç', '–∫–∏', '–µ–¥', '–æ—Å', '—Ç—å', '–∏–Ω', '–Ω–æ–≥–æ', '–Ω–∞', '–Ω—ã', '–¥—É', '–∫–∞', '–µ–º', '–µ—á', '–ø—Ä', '–∏—Ö', '–¥–∞', '–ø–∞', '–±–æ', '—ç—Ç–æ', '–≥–æ', '–ª–∞', '–¥–∏', '–Ω–∏', '–∫—É', '–±—ã', '–æ–±', '–∑–∞', '–º–∏', '–µ–Ω', '–µ–≤', '–µ—Å', '—Å–∏', '–µ—Ç', '–∏—Ç', '–º–æ', '—è–≤', '–ø–æ', '–ª—å', '–∏–∏', '–∏—Å', '–ª—è', '–∏–∑', '–Ω–µ', '–æ–≤', '–µ–ª', '–ª–µ', '—Ä–æ', '—Ä–∏', '–æ–±—â', '—Å—è', '—Ä–∞', '—É–∂', '–∫–æ', '–∏–π', '—Ç—ã', '—Ç–µ', '–∞–ª', '—á—Ç–æ', '–Ω—É', '–º—É', '—Å–∞', '–∞–∫', '–ª—É', '—Å–∫–∏', '—Ä–∞–∑', '–≤–æ', '–¥–µ', '—Ç–∏', '—Å—Ç–≤', '–Ω–æ']\n"
     ]
    }
   ],
   "source": [
    "print(list(bpe_initialize(corpus_lenta, 5, 20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: –∫—Ä–æ–º–µ –º–æ—Ä—Ñ–µ–º –∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ —Å–ª–æ–≤, –≤ —Å–ø–∏—Å–∫–µ –ø–æ—è–≤–∏–ª–∏—Å—å –æ—Ç–¥–µ–ª—å–Ω—ã–µ —á–∞—Å—Ç–æ—Ç–Ω—ã–µ —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞: \"—á—Ç–æ\", \"—Ä–∞–∑\", \"—ç—Ç–æ\". –°–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π —Ç–æ–∫–µ–Ω - \"–Ω–æ–≥–æ\" —Å 4 —Å–∏–º–≤–æ–ª–∞–º–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–∞–Ω', '–≥–ª–∞', '—Å–∫–æ–≥–æ', '–ø—Ä–∞–≤', '—Å–∫–æ–π', '–±—É', '–¥–ª—è', '—Ö–æ', '—Ç—É', '–º–∞', '–≤–∞', '–ª—é', '–µ–∂', '—Ä—É', '—Å–µ', '—Å–≤–æ', '–µ—Ç—Å—è', '–µ–≥–æ', '–ø–æ–ª', '—Å–æ', '—Å–∫–æ', '–¥–æ', '–ø–æ–¥', '–ª–∏', '—Ü–∏', '–≥–∞', '—Å—É', '–Ω–æ–º', '–Ω—ã—Ö', '–∂–∏', '—Ç–æ', '–ö–∞–∫', '–º–∏–ª–ª–∏', '–Ω–∏–∫', '–µ–π', '–º–æ–∂', '–≤–∏', '–ø–∏', '—á–∞', '–ø—Ä–∏', '—Ç–∞', '–≥—Ä–∞', '–Ω–∞—è', '–µ—Ä', '–≤—É', '–≤—ã', '–∏–ª', '–¥–æ–ª', '–±–∏', '–∫–æ–º', '–∑–∏', '–ß–µ—á', '–∞–µ—Ç', '–æ—Ç', '–ø—É', '–ª–æ', '—Å–∫–∞', '–ê–ù', '–Ω–æ–π', '—Ä–µ', '–æ—Ä', '—Å—Ç', '00', '–∑—ã', '–∫–∏', '—Ç–∞–∫–∂', '–ù–∞', '–µ–¥', '–±–ª–∏', '–±–∞', '–æ—Å', '—Ç—å', '–∏–Ω', '—Ü–∏—è', '–Ω–æ–≥–æ', '—Ä—è', '–∞–≤', '–Ω–∞', '–Ω—ã', '–¥—É', '–∫–æ–π', '–∫–∞', '–µ–º', '–≤—è', '–≤–µ—Ä', '–µ—á', '–ø—Ä', '–∏—Ö', '–º–µ', '–¥–∞', '–ø–∞', '–Ω—è', '—à–µ–Ω–∏', '–±–æ', '—Ñ–∏', '–†–æ—Å—Å–∏–∏', '–Ω—ã–º', '—Å–æ–æ–±—â', '–ò–Ω', '—ç—Ç–æ', '—Å–≤', '—ç—Ç–æ–º', '–ü–æ', '–æ–Ω', '—Ñ–æ—Ä', '–∞—Ä', '–≥–æ', '–ª–∞', '–¥–∏', '—á–∏', '–Ω–∏', '–ò–Ω—Ç–µ—Ä', '—è—Ç', '–≥—É', '–∫—É', '–±—ã', '–º—ã', '–Ω—ã–π', '–∫—Ä–∞', '–æ–±', '–∑–∞', '–ò–ê', '–º–∏', '—Ä–æ—Å—Å–∏–π', '–µ–Ω', '–Ω—É—é', '–µ–≤', '—Å–æ–æ–±—â–∞–µ—Ç', '–µ—Å', '—Å–∏', '–µ—Ç', '–≥–æ–¥–∞', '–∏—Ç', '–µ–∑', '—Ü–µ–Ω', '–º–æ', '—è–≤', '—Å—Ç–≤–µ–Ω', '–†–ò', '–ø–æ', '–ø–µ—Ä', '—á–µ–ª–æ–≤', '–ª—å', '—Ä–µ–º—è', '–æ–¥', '–∏–∏', '—é—â', '–∏—Å', '–∫–µ', '–ª—è', '–∏–∑', '—é—Ç', '–Ω–µ', '–º–µ–Ω', '19', '–æ–≤', '—Ç–∏–≤', '—Ä–∞—Å', '–µ–ª', '–ª–µ', '—Ä–æ', '–µ–∫', '—Ä–∏', '–∂–∞', '–æ–±—â', '—Å—è', '—Ä–∞', '–ú–æ—Å', '—É–∂', '–∫–æ', '–∏–π', '—è—â', '—Ç—ã', '—Ç–µ', '–¥—ã', '–∞–ª', '—Ä—É–ø', '–Ω—ã–µ', '—á—Ç–æ', '–ø—Ä–µ–∑–∏–¥–µ–Ω', '—Å—å', '–µ–Ω–∏—è', '–Ω—É', '–≤—à', '–º—É', '—Å–∞', '–≥–∏', '–∞–∫', '–ª—É', '—Ä—ã', '–†–æ—Å', '—Å–∫–∏', '—Ä–∞–∑', '–≤–æ', '–¥–µ', '–ú–æ—Å–∫', '—Ç–∏', '—Å—Ç–≤', '—Å–ø', '–Ω–æ']\n"
     ]
    }
   ],
   "source": [
    "print(list(bpe_initialize(corpus_lenta, 10, 20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ø–æ—è–≤–∏–ª–∏—Å—å –¥–ª–∏–Ω–Ω—ã–µ –æ—Ç—Ä—ã–≤–∫–∏ —á–∞—Å—Ç–æ—Ç–Ω—ã—Ö —Å–ª–æ–≤: \"—á–µ–ª–æ–≤\", \"–ø—Ä–µ–∑–∏–¥–µ–Ω\", \"–†–æ—Å—Å–∏–∏\". –°–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π —Ç–æ–∫–µ–Ω - \"—Å–æ–æ–±—â–∞–µ—Ç\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vocab = bpe_initialize(corpus_lenta, 10, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"–° –ø–æ–º–æ—â—å—é —Å–∞–Ω–∫—Ü–∏–π –ø—Ä–æ—Ç–∏–≤ —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ü–∏—è –°–®–ê \n",
    "–ø—ã—Ç–∞–µ—Ç—Å—è ¬´–ø–Ω—É—Ç—å –∏ —Ç–∞–∫ –Ω–∞—Ö–æ–¥—è—â–∏–µ—Å—è –≤ –ø–ª–æ—Ö–æ–π —Ñ–æ—Ä–º–µ —Ä–æ—Å—Å–∏–π—Å–∫–æ-–∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∏–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è¬ª, \n",
    "–∑–∞—è–≤–∏–ª –ø—Ä–µ—Å—Å-—Å–µ–∫—Ä–µ—Ç–∞—Ä—å –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ –†–æ—Å—Å–∏–∏ –î–º–∏—Ç—Ä–∏–π –ü–µ—Å–∫–æ–≤, –ø–µ—Ä–µ–¥–∞–µ—Ç –∫–æ—Ä—Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç –†–ë–ö. \n",
    "¬´–≠—Ç–æ –æ—á–µ—Ä–µ–¥–Ω–æ–π –≤—Ä–∞–∂–¥–µ–±–Ω—ã–π —à–∞–≥ –ø–æ –æ—Ç–Ω–æ—à–µ–Ω–∏—é –∫ –†–æ—Å—Å–∏–∏. –ú–æ–∂–µ–º —Ç–æ–ª—å–∫–æ —Å–æ–∂–∞–ª–µ—Ç—å, \n",
    "—á—Ç–æ –æ—á–µ—Ä–µ–¥–Ω–∞—è —É—Ö–æ–¥—è—â–∞—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ü–∏—è –°–®–ê –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ—Ç –ø–Ω—É—Ç—å –∏ —Ç–∞–∫ –Ω–∞—Ö–æ–¥—è—â–∏–µ—Å—è –≤ –ø–ª–æ—Ö–æ–π —Ñ–æ—Ä–º–µ \n",
    "—Ä–æ—Å—Å–∏–π—Å–∫–æ-–∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∏–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è¬ª, ‚Äî —Å–∫–∞–∑–∞–ª –ü–µ—Å–∫–æ–≤.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpe_tokenize(text: str, vocab: set):\n",
    "    punct = re.compile(r'[ .,:!;+=?\"\"'']')\n",
    "    bag_of_tokens = []\n",
    "    text = re.sub(punct, \"\", text)\n",
    "    order = sorted(list(vocab), key=len, reverse=True)\n",
    "    for token in order:\n",
    "        if token in text:\n",
    "            bag_of_tokens.append(token)\n",
    "    return bag_of_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–º–∏–Ω–∏—Å—Ç—Ä–∞', '–ø—Ä–æ—Ç–∏–≤', '–µ—Ä–∏–∫–∞–Ω', '—Ä–æ—Å—Å–∏–π', '–æ—Å—Å–∏–∏', '–ø—Ä–µ—Å—Å', '–ø–æ–º–æ—â', '—Å–∫–∏–µ', '–∏–¥–µ–Ω', '–µ–Ω–∏—è', '–µ—Ç—Å—è', '—à–µ–Ω–∏', '—á–µ—Ä', '–∞–µ—Ç', '–µ–Ω—Ç', '–ø–µ—Ä', '—á—Ç–æ', '—Å–∫–∏', '–º–µ—Ä', '–†–æ—Å', '—Ö–æ–¥', '—Ñ–æ—Ä', '–Ω–æ–π', '—Ü–∏—è', '–æ—Ä–≥', '—Ä–∞–∂', '–Ω—ã–π', '—Å–æ', '–µ—Ä', '–æ–π', '–æ—Ç', '—â–∏', '–∫–∞', '–º–µ', '—á–∏', '–µ—Å', '—Å–∏', '–∏—Ç', '–∏—Å', '–µ–∫', '—Å—è', '—Ä–∞', '–Ω—É', '–∞–∫', '–∞–º', '–≥–∞', '—Ç–æ', '—Ç–∞', '—à–µ', '–æ–∂', '–∂–µ', '–ª–æ', '–∞–≥', '—Å—Ç', '–∏—é', '—Å-', '–∏–Ω', '–Ω–∞', '–∏—Ö', '–¥–∞', '–∑–∞', '–º–∏', '–ø–æ', '–æ–¥', '–∏–∏', '–∏–∑', '—Ä–∏', '–æ—à', '–∞–ª', '—Ç–∏', '–∞–Ω', '—å—é', '–æ–º', '–≤–∏', '–ø–µ', '–∞–¥', '–∏–ª', '–∞—è', '–æ—Ä', '—É—Ç', '—Ç—å', '–Ω—ã', '–ø—Ä', '–ø—ã', '–æ–Ω', '–µ–Ω', '–µ—Ç', '–µ–∑', '—è–≤', '—Ä–æ', '—É—Ö', '–∏–π', '–∞—Ö', '–æ—â', '—Å–∫', '–∞–∑', '–æ–≤', '—Å–µ', '–®–ê', '—Ü–∏', '–∑–∏', '–∏–≤', '—Ä–µ', '–∫–∏', '–µ–¥', '–æ—Å', '–µ–º', '–∞—Ä', '–Ω–∏', '–æ—Ö', '–ª—å', '–æ—á', '–ª–µ', '–∫–æ', '—Å–∞', '–æ–ª', '–¥–µ', '–°–®', '–Ω–æ']\n"
     ]
    }
   ],
   "source": [
    "print(bpe_tokenize(text, final_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: –ø—Ä–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ BPE –±–µ–∑ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –ø–æ—Å–ª–æ–≤–Ω–æ–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –º–Ω–æ–≥–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ —Ç–µ—Ä—è–µ—Ç—Å—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –†–µ–∞–ª–∏–∑–∞—Ü–∏—è TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import CharBPETokenizer, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ok['text'].to_csv('corpus_new.txt', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_sub = CharBPETokenizer()\n",
    "tok_sub.train('corpus_new.txt', vocab_size=6000, min_frequency=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['–≤—Å—è</w>',\n",
       " '–¥—É',\n",
       " '–º–∞</w>',\n",
       " '–≤</w>',\n",
       " '—Ç–∞–∫–æ–º</w>',\n",
       " '–∂–µ</w>',\n",
       " '–ø–æ–ª–æ',\n",
       " '–∂–µ–Ω–∏',\n",
       " '–∏',\n",
       " 'üòÅ</w>']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_sub.encode(dataset_ok.loc[1, 'text']).tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü–æ–¥—Å—á—ë—Ç TF –∏ DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = [Counter(tok_sub.encode(dataset_ok.loc[i, 'text']).tokens) for i in range(dataset_ok.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = tok_sub.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_frequency = dict()\n",
    "tokens = list(voc.keys())\n",
    "for term in tokens:\n",
    "    for count in tokenized_texts:\n",
    "        if term not in count:\n",
    "            continue\n",
    "        if term in document_frequency:\n",
    "            document_frequency[term] += 1\n",
    "        else:\n",
    "            document_frequency[term] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16441"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_frequency['–≤</w>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_matrix = lil_matrix((dataset_ok.shape[0], 6000), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/3604/1*qQgnyPLDIkUmeZKN2_ZWbQ.png\" width=\"500\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://miro.medium.com/max/3604/1*qQgnyPLDIkUmeZKN2_ZWbQ.png\",\n",
    "     width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü–æ–ª—å–∑—É–µ–º—Å—è –∏–Ω–¥–µ–∫—Å–∞–º–∏ –≤ —Å–ª–æ–≤–∞—Ä–µ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –∫–æ–ª–æ–Ω–æ–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_docs = dataset_ok.shape[0] + 1 # for computing idf\n",
    "for index in range(len(tokenized_texts)):\n",
    "    count = tokenized_texts[index]\n",
    "    for item in count.keys():\n",
    "        col_index = voc[item]\n",
    "        tf = count[item] / sum(count.values())\n",
    "        idf = n_docs / (document_frequency[item] + 1)\n",
    "        result = tf * np.log1p(idf)\n",
    "        tf_idf_matrix[index, col_index] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û–±—É—á–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(dataset_ok.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77072889, 0.77983193, 0.79112207, 0.77533286, 0.76180761])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_log = LogisticRegression(C=1, max_iter=120, n_jobs=3)\n",
    "cross_val_score(clf_log, tf_idf_matrix, y, scoring=\"f1_macro\", cv=StratifiedKFold(n_splits=5, shuffle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58090091, 0.56539705, 0.54981246, 0.59286224, 0.59702563])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_NB = MultinomialNB()\n",
    "cross_val_score(clf_NB, tf_idf_matrix, y, scoring=\"f1_macro\", cv=StratifiedKFold(n_splits=5, shuffle=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: –ø–æ—Å–∫–æ–ª—å–∫—É –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–µ—Ç—Ä–∏–∫–∞ \"f1_macro\", —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—ã–≥–ª—è–¥—è—Ç –ø–ª–æ—Ö–∏–º–∏. –¢–µ–º –Ω–µ –º–µ–Ω–µ–µ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä, –æ–±—É—á–µ–Ω–Ω—ã–π –Ω–∞ —Å–µ–º–∏–Ω–∞—Ä–µ, –∞ –Ω–∞–∏–≤–Ω—ã–π –±–∞–π–µ—Å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ö–æ–¥–Ω—ã–π —Å –Ω–∏–º –ø–æ –∫–∞—á–µ—Å—Ç–≤—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50043239, 0.50446208, 0.51254333, 0.50846296, 0.51108045])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, X, y, scoring=\"f1_macro\", cv=StratifiedKFold(n_splits=5, shuffle=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
