{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "HW2_Ignatiev.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIsG7aMk9utj"
      },
      "source": [
        "# Домашнее задание, Игнатьев Д."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQzpB4I39utp"
      },
      "source": [
        "## Функция для подсчета PMI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfttrmUs-EHz"
      },
      "source": [
        "!pip install razdel\r\n",
        "!pip install pymorphy2\r\n",
        "!pip install string\r\n",
        "import nltk\r\n",
        "nltk.download(\"stopwords\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gHcce2D9utp"
      },
      "source": [
        "from razdel import sentenize\n",
        "from razdel import tokenize as razdel_tokenize\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from collections import Counter, defaultdict\n",
        "import numpy as np\n",
        "import re\n",
        "from string import punctuation\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stops = set(stopwords.words('russian') + [\"это\", \"весь\"])\n",
        "morph = MorphAnalyzer()\n",
        "\n",
        "def normalize(text):\n",
        "    tokens = re.findall('[а-яёa-z0-9]+', text.lower())\n",
        "    normalized_text = [morph.parse(word)[0].normal_form for word \\\n",
        "                                                            in tokens]\n",
        "    normalized_text = [word for word in normalized_text if len(word) > 2 and word not in stops]\n",
        "    \n",
        "    return normalized_text\n",
        "\n",
        "def preprocess(text):\n",
        "    sents = sentenize(text)\n",
        "    return [normalize(sent.text) for sent in sents]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q75bNasf9utq"
      },
      "source": [
        "import math"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCiOS63T9utq"
      },
      "source": [
        "import gensim"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvHvuSFd9utq"
      },
      "source": [
        "dvach = open('2ch_corpus.txt', encoding=\"UTF-8\").read()\n",
        "news = open('lenta.txt', encoding=\"UTF-8\").read()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m29nLUOC9utr"
      },
      "source": [
        "news_corpus = preprocess(news)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vJgprUn9utr"
      },
      "source": [
        "def PMI_scorer(worda_count, wordb_count, bigram_count, len_vocab, min_count, corpus_word_count):\n",
        "    if bigram_count < min_count:\n",
        "        return 0\n",
        "    try:\n",
        "        bigram_prob = bigram_count / corpus_word_count\n",
        "        worda_prob = worda_count / corpus_word_count\n",
        "        wordb_prob = wordb_count / corpus_word_count\n",
        "        score = math.log(bigram_prob / (worda_prob * wordb_prob)) \n",
        "    except ZeroDivisionError:\n",
        "        return 0\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4PYrR1l9utr"
      },
      "source": [
        "ph = gensim.models.Phrases(news_corpus, threshold=0.01, scoring=PMI_scorer)\n",
        "p = gensim.models.phrases.Phraser(ph)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEqwIH-A9uts"
      },
      "source": [
        "ph2 = gensim.models.Phrases(p[news_corpus])\n",
        "p2 = gensim.models.phrases.Phraser(ph2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKtOw9b89uts",
        "outputId": "5662ba40-ac5a-4fd8-99d6-b53fd4abfa23"
      },
      "source": [
        "p2[p[news_corpus[330]]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['настоящий_время',\n",
              " 'стационар',\n",
              " 'больница_город',\n",
              " 'находиться',\n",
              " 'раненый',\n",
              " 'критический_состояние',\n",
              " 'трое',\n",
              " 'обжечь',\n",
              " 'процент',\n",
              " 'кожа']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj7cr_TQ9utt",
        "outputId": "2bb85c0f-2df6-470d-dc10-6605a1fc2b17"
      },
      "source": [
        "p2[p[news_corpus[545]]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['общий_сумма',\n",
              " 'долг',\n",
              " 'девять_тысяча',\n",
              " 'работник',\n",
              " 'образование',\n",
              " 'республика',\n",
              " 'зарплата',\n",
              " 'выплата',\n",
              " 'сентябрь',\n",
              " 'составить_миллион_рубль']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lleAhBSa9utt"
      },
      "source": [
        "## Триграммная модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH8YSPru9utt"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olUJxDZV9utu"
      },
      "source": [
        "def normalize_ngrams(text):\n",
        "    normalized_text = [word.text.strip(punctuation) for word \\\n",
        "                                                            in razdel_tokenize(text)]\n",
        "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
        "    return normalized_text"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3_xgibt-nvn",
        "outputId": "238fc260-147f-4191-f217-e4374b776987"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIHB7RHe9utu"
      },
      "source": [
        "sentences_dvach = [['<start>', '<start>'] + normalize_ngrams(text) + ['<end>'] for text in sent_tokenize(dvach)]\n",
        "sentences_news = [['<start>', '<start>'] + normalize_ngrams(text) + ['<end>'] for text in sent_tokenize(news)]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a42BTigr9utu"
      },
      "source": [
        "def ngrammer(tokens, n=2):\n",
        "    ngrams = []\n",
        "    for i in range(0,len(tokens)-n+1):\n",
        "        ngrams.append(' '.join(tokens[i:i+n]))\n",
        "    return ngrams"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvzon3ZU9utu"
      },
      "source": [
        "unigrams_dvach = Counter()\n",
        "bigrams_dvach = Counter()\n",
        "trigrams_dvach = Counter()\n",
        "\n",
        "for sentence in sentences_dvach:\n",
        "    unigrams_dvach.update(sentence)\n",
        "    bigrams_dvach.update(ngrammer(sentence))\n",
        "    trigrams_dvach.update(ngrammer(sentence, n=3))\n",
        "\n",
        "\n",
        "unigrams_news = Counter()\n",
        "bigrams_news = Counter()\n",
        "trigrams_news = Counter()\n",
        "\n",
        "for sentence in sentences_news:\n",
        "    unigrams_news.update(sentence)\n",
        "    bigrams_news.update(ngrammer(sentence))\n",
        "    trigrams_news.update(ngrammer(sentence, n=3))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhWbPB7i9utv"
      },
      "source": [
        "from scipy.sparse import dok_matrix"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyqvrUPK9utv"
      },
      "source": [
        "matrix_dvach = dok_matrix((len(bigrams_dvach), \n",
        "                   len(unigrams_dvach)), dtype=np.float32)\n",
        "id2word_dvach = list(unigrams_dvach)\n",
        "word2id_dvach = {word:i for i, word in enumerate(id2word_dvach)}\n",
        "\n",
        "id2bigram_dvach = list(bigrams_dvach)\n",
        "bigram2id_dvach = {bigram:i for i, bigram in enumerate(id2bigram_dvach)}\n",
        "\n",
        "for ngram in trigrams_dvach:\n",
        "    split = ngram.split(\" \")\n",
        "    bigram = split[0] + \" \" + split[1]\n",
        "    word = split[2]\n",
        "    matrix_dvach[bigram2id_dvach[bigram], word2id_dvach[word]] = (trigrams_dvach[ngram]/\n",
        "                                                                     bigrams_dvach[bigram])\n",
        "    # [bigram2id_dvach[bigram]][word2id_dvach[word]]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_9-O9Pm9utv",
        "outputId": "491ddf10-d497-43f5-a09d-c1db30d60618"
      },
      "source": [
        "matrix_dvach.get_shape()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1032321, 189517)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy2dHphw9utw"
      },
      "source": [
        "# создадим матрицу вероятностей перейти из 1 слов в другое\n",
        "matrix_news = dok_matrix((len(bigrams_news), \n",
        "                   len(unigrams_news)), dtype=np.float32)\n",
        "id2word_news = list(unigrams_news)\n",
        "word2id_news = {word:i for i, word in enumerate(id2word_news)}\n",
        "\n",
        "id2bigram_news = list(bigrams_news)\n",
        "bigram2id_news = {bigram:i for i, bigram in enumerate(id2bigram_news)}\n",
        "\n",
        "# вероятность расчитываем точно также\n",
        "for ngram in trigrams_news:\n",
        "    split = ngram.split(\" \")\n",
        "    bigram = split[0] + \" \" + split[1]\n",
        "    word = split[2]\n",
        "    matrix_news[bigram2id_news[bigram], word2id_news[word]] =  (trigrams_news[ngram]/\n",
        "                                                                     bigrams_news[bigram])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8n564Cy9utw"
      },
      "source": [
        "\n",
        "def generate(matrix, id2word, id2bigram, word2id, bigram2id, n=100, start='<start> <start>'):\n",
        "    text = []\n",
        "    current_idx = bigram2id[start]\n",
        "    shape = matrix.get_shape()\n",
        "    \n",
        "    for i in range(n):\n",
        "        chosen = np.random.choice(shape[1], p=matrix.getrow(current_idx).toarray().flatten())\n",
        "        # chosen = np.random.choice(matrix.shape[1], p=matrix[current_idx])\n",
        "        new_word = id2word[chosen]\n",
        "        text.append(id2word[chosen])\n",
        "        \n",
        "        bigram = id2bigram[current_idx]\n",
        "        next_bigram = bigram[bigram.find(\" \") + 1:] + \" \" + new_word\n",
        "        \n",
        "        if new_word == '<end>':\n",
        "            current_idx = bigram2id['<start> <start>']\n",
        "        else:\n",
        "            current_idx = bigram2id[next_bigram]\n",
        "    return ' '.join(text)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj7CMIIPAcS2"
      },
      "source": [
        "### Новые тексты"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNi3IYmj9utw",
        "outputId": "343e5454-c9b7-487d-9ead-8f750e206a75"
      },
      "source": [
        "print(generate(matrix_dvach, id2word_dvach, id2bigram_dvach, word2id_dvach, bigram2id_dvach).replace('<end>', '\\n'))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "я тоже в деревни как бы надо выкидывать мультик нахуй все \n",
            " аккаунт тоже с малолетства зависала на чатурбейтах шлюховала и описывался парад проституток \n",
            " и ты все еще здесь собираю картиночки и комиксы делюсь с вами каши не сваришь но обезвоживание мне теперь ничего не производится ничего а её батя продать запись на этот счёт \n",
            " если у тебя не пидорнули фантазер \n",
            " узрите же как видишь о найс мерки мои убили \n",
            " бред 28 48 но их ничтожно мало \n",
            " это потому что она вам и доказательство что пиздоглазые не могут попасть летающие снаряды по этой фотке не\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb2wHj8k_a1m"
      },
      "source": [
        "del matrix_dvach"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAHBo_CC9utw",
        "outputId": "4da95183-fa1f-4795-e464-0e1c42eb5844"
      },
      "source": [
        "print(generate(matrix_news, id2word_news, id2bigram_news, word2id_news, bigram2id_news).replace('<end>', '\\n'))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "планируется что в вопросе ликвидации сторон \n",
            " национальная ассоциация телевещателей и журнал маркетинг и маркетинговые исследования в первый раз это является нарушением закона если оно взяло на себя ответственность за другие террористические акции на мавзолее осмоловский позвонил в телестудию секретный протокол встречи представителей службы безопасности проверяющих проводили в эти города будут опрыскиваться и дальше продолжать переговоры с министерством связи и так далее \n",
            " про самое важное исключить возможность того что происходит на фоне продолжения борьбы за контроль над каналом в который войдут губернаторы и руководители американского eximbank нанедавней встрече в кремле говорится в документе по мнению руководства хорошо владеющий ситуацией\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTh9rUYeASye"
      },
      "source": [
        "del matrix_news"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "begargCcAf5Q"
      },
      "source": [
        "### Старые тексты"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "SQ6_Ku-39utx",
        "outputId": "4b11360a-458b-4eb6-e784-b257427c70f6"
      },
      "source": [
        "print(generate(matrix_dvach, id2word_dvach, word2id_dvach).replace('<end>', '\\n'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "они потеряли со всеми \n",
            " молодец \n",
            " а остальные 4 имя той толпы следовательно вставлять как только стареть и фаерфаксе свг спрайт \n",
            " и пропустить что это чтоб задыхалась так будь ты хуй на 10 назад \n",
            " от 20 черепов – я посмотрю как худая смотрит \n",
            " с четвёртого энергоблока \n",
            " одним выстрелом расхуярить чтобы было видно что совершил преступление перед прыжком скажу только малая зона в дни месяцы слабо подумать что была мечта казуала \n",
            " с крайностями \n",
            " блин сделали потому что он спит а не дна хуже чем китай \n",
            " год поставил \n",
            " св \n",
            " геноцида ксеносов в\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "wwtrvHSw9utx",
        "outputId": "7b61e885-4b1c-4db5-850e-549e1b715d2e"
      },
      "source": [
        "print(generate(matrix_news, id2word_news, word2id_news).replace('<end>', '\\n'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "иначе представители таких как сми сказал генерал колонна из юар нельсон автор сюжета было совершено покушение на своих наблюдателей передает риа новости \n",
            " по полному расчету с первым шагом на 15 сентября \n",
            " на средства буквально за рубежом \n",
            " полностью поддержала точку зрения на внешних врагов то будут очень похож на политический советник президента около ста семей \n",
            " владелец предприятия \n",
            " касаясь ситуации в длинном перечне 85 лет и оружия был обнаружен тайник с 1993 по умолчанию не поможет ведь никто не имеет самые решительные действия в пресс-службе всемирного банка \n",
            " в порту сочи началась эпидемия гриппа достигнет рекордного уровня\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xbFohs9ArjU"
      },
      "source": [
        "### Наблюдение:\r\n",
        "после добавления триграмм последовательности слов в тексте в целом стали более осмысленными. Например,\r\n",
        "\"исключить возможность того что происходит\" или \"это является нарушением закона\"."
      ]
    }
  ]
}